{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the Data\n",
    "\n",
    "## First we answer basic questions about our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: What is the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types:\n",
      "cx          int64\n",
      "cy          int64\n",
      "cz          int64\n",
      "unmasked    int64\n",
      "synapses    int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Read in data\n",
    "df = pd.read_csv('../output.csv')\n",
    "print \"Data types:\"\n",
    "print df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data\n",
    "\n",
    "### Data set contents\n",
    "\n",
    "The data set is a table consisting of the following columns: \"cx\", \"cy\", \"cz\", \"unmasked\", and \"synapses\". there are 61776 rows, each corresponding to a cortical volumn called \"bins\" henceforth. \n",
    "\n",
    "\"cx\", \"cy\", and \"cz\" denote the unique location of the bin. \"synapses\" is an integer count of the number of synapses found within the bin. \n",
    "Each bin was comprised of many individual voxels of the EM image. A synapse could technically be found at any given voxel. However, a subset of these voxels were pre-determined by the experimenters to contain material that are not synapses (i.e. cell bodies). These voxels were considered \"masked\". Thus the \"unmasked\" voxels comprise the subset area of each bin in which a synapse may reside. \n",
    "\n",
    "We found no values within our data set that were \"bad\": no NaNs, Infs or nonsensical values. All numbers were integers as expected. Synapses and unmasked values were nonnegative. \n",
    "\n",
    "### Statistics\n",
    "* There are roughly  7.7e6 total synapses across the entire cortical volume\n",
    "* The maximum number of synapses per bin is 507\n",
    "* The mean number of synapses per bin is 124.7\n",
    "* The median number of synapses per bin is 144\n",
    "* The standard deviation of synapses per bin is 92.0\n",
    "* The dimensions of each bin is 3.9 x 3.9 x 5.55 um^3\n",
    "* The dimensions of the entire scanned cortical volume is 421.2 x 202.8 x 61.1 um^3\n",
    "\n",
    "### Exploritory Analysis - Raw Synapse Count\n",
    "\n",
    "#### Distribution of Synapses\n",
    "Shown is a histogram of synapse count across all bins of the dataset.\n",
    "<img src=\"./figs/AndrewFigs/histSyn.png\" data-canonical-src=\"./figs/AndrewFigs/histSyn.png\" width=\"600\" />\n",
    "* There are a significant amount of zero or low-count bins. Later we realized that this was due to masking.\n",
    "* Bins with higher synapse counts seem to be roughly normally distributed\n",
    "\n",
    "To get a sense of outliers, we boxplotted synapse count.\n",
    "<img src=\"./figs/AndrewFigs/boxSyn.png\" data-canonical-src=\"./figs/AndrewFigs/boxSyn.png\" width=\"600\" />\n",
    "Only two bins were determined to be outliers.\n",
    "\n",
    "#### 1-Dimensional Marginal Distributions\n",
    "Shown are the marginal distributions of synapse count for along the cortical dimensions of x, y, and z\n",
    "<img src=\"./figs/AndrewFigs/histX.png\" data-canonical-src=\"./figs/AndrewFigs/histX.png\" width=\"600\" />\n",
    "<img src=\"./figs/AndrewFigs/histY.png\" data-canonical-src=\"./figs/AndrewFigs/histY.png\" width=\"600\" />\n",
    "<img src=\"./figs/AndrewFigs/histZ.png\" data-canonical-src=\"./figs/AndrewFigs/histZ.png\" width=\"600\" />\n",
    "A couple observations are apparent:\n",
    "* synapse count is relatively uniform across x and z dimensions \n",
    "* synapse count is not uniform across y dimension. The drop-off in synapse count at higher values of y is primarily due to edge effects of the data volume\n",
    "* However, even away from the edges, there seems to be a slight negative trend beween synapse density and y-coordinate\n",
    "\n",
    "#### 2-Dimensional Marginal Distributions\n",
    "Shown are the heatmaps of synapse count.\n",
    "<img src=\"./figs/AndrewFigs/heatXY.png\" data-canonical-src=\"./figs/AndrewFigs/heatXY.png\" width=\"600\" />\n",
    "<img src=\"./figs/AndrewFigs/heatXZ.png\" data-canonical-src=\"./figs/AndrewFigs/heatXZ.png\" width=\"600\" />\n",
    "<img src=\"./figs/AndrewFigs/heatYZ.png\" data-canonical-src=\"./figs/AndrewFigs/heatYZ.png\" width=\"600\" />\n",
    "* The z-dimension is much courser than x and y. There are far less z-layers than x and y.\n",
    "* The edge effects affecting the y-dimension distribution in the previous section are apparent in the y-z heatmap. Each Z layers had a variable edge cutoff in the y-dimension\n",
    "* The x and z dimensions fairly \"rectangular\". There are significant edge effects here.\n",
    "* Certain z-layers appear to be more dense than others. We investigate this further later.\n",
    "\n",
    "### Exporatory Analysis - Weighted Synaptic Count\n",
    "At this point, we realized the significance of the unmasked data. We incorporated unmasked considerations into our subsequent exploratory analysis.\n",
    "\n",
    "#### Distribution of Unmasked Count\n",
    "Shown is a box plot of the unmasked count:\n",
    "<img src=\"./figs/AndrewFigs/boxUm.png\" data-canonical-src=\"./figs/AndrewFigs/boxUm.png\" width=\"600\" />\n",
    "* There are no outliers \n",
    "* There is a lower tail\n",
    "\n",
    "#### Synapse vs. Unmasked \n",
    "Shown is a joing plot of Synapse vs. unmasked data.\n",
    "<img src=\"./figs/AndrewFigs/jointPlotSynUm.png\" data-canonical-src=\"./figs/AndrewFigs/jointPlotSynUm.png\" width=\"600\" />\n",
    "* note that the marginal distribution of synapse count is a repeat of what was shown before\n",
    "* now we can appreciate the degree to which synapse count is affected by unmasked count. Virtually all the bins with zero-to-low synapse counts were the unmasked count also being zero-to-low\n",
    "* There is an overall positive correlation between unmasked and synapse data, as one might expect. \n",
    "* Most of the data lies in a dense region of relatively high unmasked and synapse count. Within this region, there is less correlation between synapse and unmasked count.\n",
    "\n",
    "#### Weighted Synapse\n",
    "At this point we did two things with the data:\n",
    "1) We defined \"weighted\" synapse count of a bin as the raw synapse count divided by the unmasked count\n",
    "2) We discarded all bins with lower than 50% of voxels unmasked\n",
    "\n",
    "Shown is the distribution of weighted synapses over all bins that met the 50% unmasked requirement:\n",
    "<img src=\"./figs/AndrewFigs/histW.png\" data-canonical-src=\"./figs/AndrewFigs/histW.png\" width=\"600\" />\n",
    "We have successfully pruned out the subset of bins with zero-to-low synapse/unmasked count. The remaining data looks fairly normally distributed.\n",
    "All subsequent analysis was carried out with weighted and thresholded synapse count, and is referred to as \"weighted synapse count\".\n",
    "\n",
    "## Hypothesis Testing\n",
    "\n",
    "### Statistical Test\n",
    "We decided to test whether the weighted synapse count follows a poisson distribution. \n",
    "\n",
    "#### Test Definition\n",
    "\n",
    "* $\\lambda$ is average number of synapses per bin\n",
    "* $X_i$ is the number of synapses in a 3D bin $i \\in \\{1, 2, ..., N\\}$\n",
    "* $\\chi^2 = \\sum{\\frac{(Observed-Expected)^2}{Expected}}$\n",
    "* $H_0$: $X_i$ is Poisson (with rate $\\lambda$)\n",
    "* $H_1$: $X_i$ is not Poisson\n",
    "\n",
    "#### Algorithm\n",
    "* Combine the tails and/or coarsen bins of $X_i$ histogram so that all cells have at least 5 observations (http://www.itl.nist.gov/div898/handbook/eda/section3/eda35f.htm)\n",
    "* New histogram $O_j$ is the number of observations (3D bins) with $k$ synapses, where $k \\in j^{th}$ cell, $j \\in \\{1,2,...,m\\}$ (m total cells)\n",
    "* Compute $E_j = \\sum_{k \\in cell(j)}{N\\frac{\\lambda^k exp(-\\lambda)}{k!}}$, $j \\in \\{1,2,...,m\\}$\n",
    "* $\\chi^2 = \\sum_{j=1}^{m}{\\frac{(O_j-E_j)^2}{E_j}}$\n",
    "* Degrees of freedom = $m-2$\n",
    "* Significance level $\\alpha = 0.05$\n",
    "* If $\\chi^2 > \\chi^2_{1-\\alpha,m-2}$, we reject the null hypothesis.\n",
    "* Otherwise, there is not sufficient evidence to conclude that $X_i$ is not Poisson.\n",
    "\n",
    "#### Simulated Data\n",
    "We simulated data from poisson as well as geometric distributions under a range of sample sizes. We tested each set of simulated data under th Null Hypothesis that the data set was a poisson distribution. Thus, data generated by a poisson process was considered the \"Null Model\", while data generated by a geometric distribution was considered the \"Alt Model\"\n",
    "\n",
    "#### Simulated Data Result\n",
    "Shown is a the power of our statistical test over a range of sample sizes\n",
    "\n",
    "<img src=\"./figs/AndrewFigs/poissSim.png\" data-canonical-src=\"./figs/AndrewFigs/poissSim.png\" width=\"600\" />\n",
    "\n",
    "* As expected, data under the null model was rejected at alpha level over all sample sizes\n",
    "* The power of our statistical test increased with sample size, approaching 1.0\n",
    "\n",
    "#### Statistical Test on Weighted Data\n",
    "We applied our test to our weighted synapse data by setting $\\lambda$ to the observed mean of weighted synapse count. \n",
    "\n",
    "Shown is a comparison of the observed vs. expected weighted synapse counts:\n",
    "\n",
    "<img src=\"./figs/AndrewFigs/chiObsExp.png\" data-canonical-src=\"./figs/AndrewFigs/chiObsExp.png\" width=\"600\" />\n",
    "\n",
    "* chi-squared statistic:  inf\n",
    "* p-value:  0.0\n",
    "* Clearly the data was not poisson distributed\n",
    "* We should have used a model with more than one degree of freedom (i.e. normal distribution). That way we could individually vary/fit a parameter for mean as well as a parameter for spread.\n",
    "\n",
    "## Classification\n",
    "\n",
    "### Problem Definition\n",
    "We divided the bins according to Z layer, and attempted to classify the Z-layers based on weighted synapse count.\n",
    "\n",
    "#### Assumptions\n",
    "* The set of mean synapse density of an entire Z-layer can be classified into 2 groups: $W_i$\n",
    "* $W_i = \\{\\text{High density},\\text{  Low density}\\}$  \n",
    "* The distribution of synapse density of each group is normally distributed \n",
    "\n",
    "#### Classification Probelm\n",
    "* We then randomly choose a small grid, and use the $X$ and $Y$ position to predict this grid belongs to high or low density.  \n",
    "  \n",
    "* $N$ is the number of synapses (observations)\n",
    "* $X_i = X\\text{ position} $  \n",
    "* $Y_i = Y\\text{ position} $  \n",
    "* $H_0 = N \\perp\\!\\!\\!\\perp X, Y$ positions\n",
    "* $H_1 = N \\text{ is not} \\perp\\!\\!\\!\\perp X, Y$ positions  \n",
    "* The objective is to minimize the expected error:  \n",
    "* $E[l] = \\sum_{n=1}^{\\infty}I(\\hat{W_i} \\neq W_i)$ where $I$ is the indicator function.\n",
    "\n",
    "Classification methods:\n",
    "\n",
    "* lda (Linear Discriminant Analysis): No parameter.\n",
    "* qda (Quadratic Discriminant Analysis): No parameter.\n",
    "* svm (Support Vector Machine): Linear kernel, penalty parameter set to 0.001, to improve computation time.\n",
    "* knn (K-Nearest Neighbours): Number of neighbors set to 3.\n",
    "* rf (Random Forest): Default values except maximum depth set to 5.\n",
    "\n",
    "### Implementation / Setup\n",
    "\n",
    "#### Example x-y grid\n",
    "Shown is an example of a 5-by-5 grid of bins.\n",
    "<img src=\"./figs/AndrewFigs/chiObsExp.png\" data-canonical-src=\"./figs/AndrewFigs/chiObsExp.png\" width=\"600\" />\n",
    "\n",
    "We average the weighted synapse density across the 25 bins to produce a single \"grid mean\". \n",
    "\n",
    "#### Grid Means by Z-layer,\n",
    "We randomly sample 1000 grids from each Z-layer and visualize the distribution of grid means\n",
    "\n",
    "<img src=\"./figs/AndrewFigs/gridDistByLayer.png\" data-canonical-src=\"./figs/AndrewFigs/gridDistByLayer.png\" width=\"600\" />\n",
    "\n",
    "#### Separating the Z-layers into 2 Groups\n",
    "We then took the means of the grid-means of each Z-layer (to have 11 means total), and performed K-means clustering to isolate two groups: one \"high-response\" group and one \"low-response\" group.\n",
    "\n",
    "<img src=\"./figs/AndrewFigs/kmeansGrid.png\" data-canonical-src=\"./figs/AndrewFigs/kmeansGrid.png\" width=\"600\" />\n",
    "\n",
    "The low-response group comprised of 8 Z-layers, while the high-response group comprised of 3 Z-layers\n",
    "\n",
    "#### Grid Means Across the 2 Groups\n",
    "Shown is the distribution of grid-means of each group\n",
    "\n",
    "<img src=\"./figs/AndrewFigs/pdf.png\" data-canonical-src=\"./figs/AndrewFigs/pdf.png\" width=\"600\" />\n",
    "\n",
    "It is immediately obvious that the two groups have a significant overlap in grid means.  Classification is not expected to be very successful.\n",
    "\n",
    "### Classification Results\n",
    "\n",
    "#### Accuracy of each classifier\n",
    "Accuracy of Nearest Neighbors: 0.75 (+/- 0.01)\n",
    "Accuracy of Linear SVM: 0.80 (+/- 0.01)\n",
    "Accuracy of Random Forest: 0.80 (+/- 0.01)\n",
    "Accuracy of Linear Discriminant Analysis: 0.80 (+/- 0.01)\n",
    "Accuracy of Quadratic Discriminant Analysis: 0.80 (+/- 0.01)\n",
    "\n",
    "#### Interpretation\n",
    "The five classifiers tested had accuracies between 75-80%, which is better than chance. However, these numbers are only slightly at or above the maximum prior probability of 73%. This means that our classifiers are only slightly better than just choosing the class with the maximum prior 100% of the time, assuming we trust the priors. Taking into account the observed synapse density provides little added information, which is not surprising given the large overlap in observed densities from the two classes. If we wanted to distinguish between similar populations of Z layers but with different priors from another dataset, our accuracy would decrease accordingly.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: How many Nan, Inf, or other \"bad\" data values are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nan values by column:\n",
      "cx          0\n",
      "cy          0\n",
      "cz          0\n",
      "unmasked    0\n",
      "synapses    0\n",
      "dtype: int64 \n",
      "\n",
      "Number of rows with nan values: 0 \n",
      "\n",
      "Number of inf values by column:\n",
      "cx          0\n",
      "cy          0\n",
      "cz          0\n",
      "unmasked    0\n",
      "synapses    0\n",
      "dtype: int64 \n",
      "\n",
      "Number of rows with inf values: 0 \n",
      "\n",
      "Number of negative values by column:\n",
      "cx          0\n",
      "cy          0\n",
      "cz          0\n",
      "unmasked    0\n",
      "synapses    0\n",
      "dtype: int64 \n",
      "\n",
      "Number of rows with negative values: 0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "isNan = df.isnull()\n",
    "isInf = np.isinf(df)\n",
    "isNeg = df < 0\n",
    "\n",
    "print \"Number of nan values by column:\"\n",
    "print isNan.sum(), \"\\n\"\n",
    "print \"Number of rows with nan values:\", isNan.sum(1).sum(), \"\\n\"\n",
    "\n",
    "print \"Number of inf values by column:\"\n",
    "print isInf.sum(), \"\\n\"\n",
    "print \"Number of rows with inf values:\", isInf.sum(1).sum(), \"\\n\"\n",
    "\n",
    "print \"Number of negative values by column:\"\n",
    "print isNeg.sum(), \"\\n\"\n",
    "print \"Number of rows with negative values:\", isNeg.sum(1).sum(), \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion:\n",
    "There is no \"bad\" data in our data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: What is the \"size\" of our data set?\n",
    "   * how many synapses are there?\n",
    "   * how many bins are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 7704178 total synapses in the data.\n"
     ]
    }
   ],
   "source": [
    "nSyn = df['synapses'].sum()\n",
    "print \"There are\", nSyn, \"total synapses in the data.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 61776 total 3D bins.\n"
     ]
    }
   ],
   "source": [
    "nBins = df['synapses'].count()\n",
    "print \"There are\", nBins, \"total 3D bins.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
